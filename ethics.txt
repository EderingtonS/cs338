Sam Ederington

First Scenario: InstaToonz Bug

The main ethical quandry you face in this scenario is whether or not to report a bug that may land you in legal danger as well as affect your reputation.

As the person who found the bug, reporting it is your decision. You also have the right to discuss potentially criminal activity with a lawyer, and they are forbidden from reporting it unlesss immediate danger would be caused.
InstaToonz owns the product and has the rights to probably most of the information in it. 
Customers of InstaToonz have the right to know that their information and privacy is at risk, potentially monetary if they have ever shared financial details with or over the app.

I would like to know the terms and conditions of InstaToonz, specifically regarding its policies regarding information privacy as well as whether or not my discovering the bug may or may not be legal.

Reporting the bug or not reporting the bug comes with consequences.
If you report the bug, you can get sued and possibly found guilty or not, and your reputation may be damaged. If you don't report the bug, you may be constantly worried and guilty about your failure to take action.
If you report the bug, InstaToonz can either resolve the bug or leave it. If they do the former, it might incur some costs somehow. If they leave it, they're at risk of it being publicized and incriminating them in failing to safeguard information and also cause them to loose their customer base.
InstaToonz can also decide to sue you if you report the bug. If they do, they stand to risk their reputation and userbase again, but can potentially discourage other people from poking around in their systems.
If you do not report the bug, InstaToonz may find it on their own and resolve it, but they are still at risk of losing huge amounts of customers if someone else also discovers and exploits the vulnerability.
If you report it, customers will be safer either due to security changes or when you publicize the flaw in moving to other platforms. IF you don't report the bug, customers will still be at risk of all of their contacts and communications being observed and stolen.

The ACM code of ethics obligates reporting of vulnerabilities, and if there is no attempt to fix them report the vulnerability to the public unless harm is likely greater than the knowledge. It ultimately says "Before reporting risks, a computing professional should carefully assess relevant aspects of the situation." Whether that is for the report to the organization or to the public or to either is guesswork.

The first thing is to consult with a lawyer on the legality of your actions! They cannot report the crime, so doing so is perfectly safe, and gives you more information on how much harm you are risking by reporting.
Secondly, reporting the bug should be done in a way to try and maintain your safety while doing so. If you do so confidentially without InstaToonz identifying you, you can act like one of the disclosure organizations and publicize the information after a few months.
Hopefully, you don't get identified and don't get sued, or at least don't get sued. I would not expect a reward from reporting the bug given InstaToonz's policies and actions. If you do get sued, at least you have already made contact with relevant legal authorities.



Second Scenario: Beerz Location

The main ethical quandry you face is how to reconcile protecting customers' privacy with making a succesful (profitable) app, and what actions an ethical lead developer can take to accomplish both.

You are in charge of making the second update and scheduling the team to implement it (as long as you don't get fired). You also 
Your CEO (and profit driven employees/investors/board members) have the right to give out work according to the interests of the company as they see them and fire employees if they feel necessary.
Your CTO (and information-protection driven employees) have the right to perform work according to their interest in the subject, as well as quit if they feel their concerns are not being represented or whistle blow to consumers.
Customers have the right for their infromation to be protected according to whatever terms they signed up with, and probably more depending on the contract.

Possible actions include:
Quitting publically and blowing the whistle on the CEO and corporate interests in the app, possibly killing the startup if privacy was a major starting point and getting you out of an enjoyable work environment and possibly red flagging you for potential employers.
Maintain the development course as if the meeting didn't happen, focussing on properly implementing secure data storage and scrubbing algorithms, and not releasing the whole update until a course is confirmed. Probably won't lead to any positive or negative changes, but could lead to replacement if management gets too invested in immediately implementing the data selling scheme. Potentially involves selling user data if that is what management decides.
Informing the 1.1 team of the vulnerability immediately and focussing on protecting existing data now and forever. Probably gets you replaced, but the app stays secure information wise, at least for now.
Money is good! Kidnap the CEO and ransom her and the customer's information and threaten to whistleblow on the company! Turn to a life of crime, harming everybody (probably inclluding you) in the process!

The ACM encourages supporting privacy of users of computing, and heavily discourages re-acquiring nonessential data. In fact, it suggests only minimal personal data should be collected in the first place.

Firstly, inform the 1.1 team and encourage they adjust their get request and storage to help protect user information privacy. This can be done off the record and should be done in order to properly secure the information, and if they were also brought in under the CTO or lead by them then they are low risk. Secondly, look over the terms and conditions and privacy notice for the application, and if there is even the slightest bit of concern over a contradiction, ask the legal team about it (if there is one) or let whoever is in charge of that know of your concern. Additionally, focus the team's time on implementing features that do not risk user privacy first, as well as security for in case it is attacked. Lastly, see if there is a way you can get the startup to survey users on the importance of their information privacy. Talk with team members about it, so that in the next meeting you can bring up lots of concerns and generally be annoying and stall about having to decide on it until later.
This might get you fired, depending on the people surrounding you and the management, but I think there's a good chance it wouldn't.
